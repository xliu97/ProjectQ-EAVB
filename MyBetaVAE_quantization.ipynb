{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for this part referred to the quantization notebook provided by TA Konan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3ujNk_5NXEp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import torchvision   \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import zipfile\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "crGavjiIHexB",
    "outputId": "6a6330d3-aa2b-4f73-e89d-be1e810da89e"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install torchvision\n",
    "!pip3 install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4y6bY1aLfGt",
    "outputId": "3d1948e9-1506-4abc-db62-d026b1f1c4b6"
   },
   "outputs": [],
   "source": [
    "# data download source is not shown due to fair use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlAVjSPUvK_b",
    "outputId": "27b0eff1-671d-4ffb-a3a2-212a486edd64"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(use_cuda, device, torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nqwxeyw2p5Nd"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbjVnNFTNSEM"
   },
   "outputs": [],
   "source": [
    "class MyBetaVAE(nn.Module):\n",
    "    def __init__(self, in_channels, z_dim, beta): # image should have size 64*64\n",
    "        super(MyBetaVAE, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.beta = beta\n",
    "\n",
    "        # hidden_dims = [in_channels, 32, 64, 128, 256, 512]\n",
    "        hidden_dims = [in_channels, 32, 64, 128, 256]\n",
    "        self.encoder_final_size = 16\n",
    "        self.hidden_dims = hidden_dims\n",
    "\n",
    "        # encoder\n",
    "        encoder_layers = []\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            encoder_layers.append(nn.Sequential(\n",
    "                                        nn.Conv2d(hidden_dims[i], hidden_dims[i+1], kernel_size=3, stride=2, padding=1),\n",
    "                                        nn.BatchNorm2d(hidden_dims[i+1]),\n",
    "                                        nn.LeakyReLU()\n",
    "                                  ))\n",
    "        \n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        self.mu = nn.Linear(hidden_dims[-1] * self.encoder_final_size, z_dim)\n",
    "        self.logvar = nn.Linear(hidden_dims[-1] * self.encoder_final_size, z_dim)\n",
    "\n",
    "        # decoder\n",
    "        self.decoder_in = nn.Linear(z_dim, hidden_dims[-1] * self.encoder_final_size)\n",
    "\n",
    "        decoder_layers = []\n",
    "        for i in range(len(hidden_dims)-1, 0, -1):\n",
    "            decoder_layers.append(nn.Sequential(\n",
    "                                      nn.ConvTranspose2d(hidden_dims[i], hidden_dims[i] if i == 1 else hidden_dims[i-1], kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                                      nn.BatchNorm2d(hidden_dims[i] if i == 1 else hidden_dims[i-1]),\n",
    "                                      nn.LeakyReLU()\n",
    "                                  ))\n",
    "        \n",
    "        self.decoder = nn.Sequential(*decoder_layers,\n",
    "                                     nn.Conv2d(hidden_dims[1], hidden_dims[0], kernel_size=3, padding=1),\n",
    "                                     nn.Sigmoid())\n",
    "    \n",
    "    def encode(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = torch.flatten(out, start_dim=1)\n",
    "        mu = self.mu(out)\n",
    "        logvar = self.logvar(out)\n",
    "        self.mu_value = mu\n",
    "        self.logvar_value = logvar\n",
    "        self.x = x\n",
    "        return mu, logvar\n",
    "    \n",
    "    def decode(self, x):\n",
    "        out = self.decoder_in(x).view(-1, self.hidden_dims[-1], 4, 4)\n",
    "        out = self.decoder(out)\n",
    "        return out\n",
    "    \n",
    "    def reparam(self, mu, logvar):\n",
    "        std = torch.exp(logvar / 2)\n",
    "        epsilon = torch.autograd.Variable(torch.randn_like(std))\n",
    "        return std * epsilon + mu\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        time1 = time.time()\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparam(mu, logvar)\n",
    "        time2 = time.time()\n",
    "        out = self.decode(z)\n",
    "        time3 = time.time()\n",
    "        self.x_cons = out\n",
    "        return out, z, mu, logvar, Variable(torch.tensor(time2-time1)), Variable(torch.tensor(time3-time2)) #{\"encodertime\": , \"decodertime\": }\n",
    "    \n",
    "    def loss(self):\n",
    "        reconstruction_loss = F.mse_loss(self.x_cons, self.x, reduction='sum')\n",
    "        kl_div = torch.mean(torch.sum(-0.5 * (1 + self.logvar_value - self.mu_value ** 2 - self.logvar_value.exp()), dim=1), dim=0)\n",
    "        return reconstruction_loss + self.beta * kl_div, reconstruction_loss, kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FRnLvoLCWe9"
   },
   "outputs": [],
   "source": [
    "class MyBetaVAEEncoder(MyBetaVAE):\n",
    "    \n",
    "    def __init__(self, in_channels, z_dim, beta): # image should have size 64*64\n",
    "        super().__init__(in_channels, z_dim, beta)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparam(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "class MyBetaVAEDecoder(MyBetaVAE):\n",
    "    \n",
    "    def __init__(self, in_channels, z_dim, beta): # image should have size 64*64\n",
    "        super().__init__(in_channels, z_dim, beta)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        out = self.decode(z)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lw5g4OmApVKu"
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HuORBtSpR1g"
   },
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.Resize((64, 64)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((64, 64)),\n",
    "    torchvision.transforms.ToTensor()                                              \n",
    "])\n",
    "\n",
    "def get_dataloaders(path, shuffle, portion, val_split, batch_size, test=False):\n",
    "    dataset = torchvision.datasets.ImageFolder(root=path, transform=transforms)\n",
    "    if test:\n",
    "      test_dataset = torchvision.datasets.ImageFolder(root=path, transform=test_transforms)\n",
    "      for filename in test_dataset.imgs:\n",
    "          frame_names.append(filename[0].split('/')[-1])\n",
    "\n",
    "    shuffle_dataset = shuffle\n",
    "    use_proportion = portion\n",
    "    validation_split = val_split\n",
    "    batch_size = batch_size\n",
    "    random_seed= 42\n",
    "\n",
    "    # Creating data indices for training and validation splits:\n",
    "    indices = list(range(len(dataset)))\n",
    "    use_length = int(len(dataset) * use_proportion)\n",
    "    split = int(np.floor((1 - validation_split) * len(dataset)) * use_proportion)\n",
    "    if shuffle_dataset:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[:split]\n",
    "    print(train_indices)\n",
    "    val_indices = indices[split:use_length]\n",
    "    print(len(train_indices), len(val_indices))\n",
    "    print(len(dataset), use_length, split)\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "  \n",
    "\n",
    "    train_dataloader = DataLoader(dataset, batch_size=batch_size, drop_last=True, sampler=train_sampler, num_workers=4)\n",
    "    val_dataloader = DataLoader(dataset, batch_size=batch_size, drop_last=True, sampler=val_sampler, num_workers=4)\n",
    "\n",
    "    if test:\n",
    "      test_sampler = SequentialSampler(train_indices)\n",
    "      test_dataloader = DataLoader(test_dataset, batch_size=batch_size, drop_last=False, sampler=test_sampler, num_workers=4)\n",
    "      return test_dataloader, test_dataloader\n",
    "    \n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXab8JXNNdH_"
   },
   "source": [
    "## Inference & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUFPXS1AZ7mw",
    "outputId": "6b184d41-ee34-4288-e7d1-564c6edd9f44"
   },
   "outputs": [],
   "source": [
    "!mkdir ./dev_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hz6nbjJJaTE4",
    "outputId": "9339a6b4-6065-4094-8ce9-aa9a920585d0"
   },
   "outputs": [],
   "source": [
    "!unzip ./unique-142p-valid.zip\n",
    "!mv ./unique-142p-valid ./dev_data/unique-142p-valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0-NF736NYga",
    "outputId": "7204dc20-225c-4a15-ed33-3233b7d5178d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = {}\n",
    "avg_loss = 0\n",
    "z_ls = []\n",
    "batch_size = 512 # 2048, 1024, 512, 256\n",
    "\n",
    "frame_names = []\n",
    "dev_loader, dev_original_loader = get_dataloaders('./dev_data', shuffle=False, portion=1, val_split=0, batch_size=batch_size, test=True)\n",
    "print(frame_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95l3RPQoTnYH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = np.genfromtxt('./scene-change.csv', delimiter=',', names=True, dtype=None, encoding=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1XEfwxrm6bcd",
    "outputId": "2ecf244b-ac16-45f9-c05b-90215d6c73e4"
   },
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEXY9F7qTIxB",
    "outputId": "593e1402-c010-4da0-f05b-ca04008aceab"
   },
   "outputs": [],
   "source": [
    "label_ls = [] # record frame1 in true_labels\n",
    "for labels in labels:\n",
    "  label_ls.append(labels[0])\n",
    "print(label_ls[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPgSsgc34II0",
    "outputId": "d78c1527-4713-48f8-a51b-2382446c2ec9"
   },
   "outputs": [],
   "source": [
    "# label for scene change 1 represent change\n",
    "true_labels = []\n",
    "for name in frame_names:\n",
    "    if name in label_ls:\n",
    "        true_labels.append(1)\n",
    "    else:\n",
    "        true_labels.append(0)\n",
    "print(len(true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okiNqH3HOKsO"
   },
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CsOylYMJU8z",
    "outputId": "4bbb2420-4903-4484-857e-11299bd3a411"
   },
   "outputs": [],
   "source": [
    "!mkdir models\n",
    "!pip3 install onnx\n",
    "!pip3 install onnxruntime\n",
    "!pip3 install py-cpuinfo\n",
    "!pip3 install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKBDsDPmx4dj",
    "outputId": "3a7ce429-8f99-43b4-dd92-70c531b39f92"
   },
   "outputs": [],
   "source": [
    "# Model and Inference\n",
    "import onnx\n",
    "import onnx.numpy_helper\n",
    "import onnxruntime\n",
    "import onnxruntime.quantization\n",
    "\n",
    "# Data Loader\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Evaluation\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Other Utilities\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "# import cpuinfo # !conda install -c conda-forge py-cpuinfo # not used in colab\n",
    "import cpuinfo\n",
    "\n",
    "\n",
    "print(\"onnx\", onnx.__version__)\n",
    "print(\"onnxruntime\", onnxruntime.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrblSjMA7fbn",
    "outputId": "a173cee9-6850-4add-eaf4-7d14753437b4"
   },
   "outputs": [],
   "source": [
    "cpuinfo.get_cpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsXcqMzlNOIK",
    "outputId": "0fda05bc-c971-4223-daa8-b687f975bb60"
   },
   "outputs": [],
   "source": [
    "!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ylRCUwvOUTE",
    "outputId": "2baab558-aa0f-4424-c4a0-713c61d198f4"
   },
   "outputs": [],
   "source": [
    "### Get Original PyTorch Model\n",
    "checkpoint = torch.load(\"./v2_best_checkpoint_epoch125.pt\", map_location=torch.device(device))\n",
    "\n",
    "in_channels, z_dim, beta = 3, 128, 0.5\n",
    "model = MyBetaVAE(in_channels, z_dim, beta)\n",
    "model.load_state_dict(state_dict=checkpoint['model'])\n",
    "model.to(device)\n",
    "model_encoder = MyBetaVAEEncoder(in_channels, z_dim, beta)\n",
    "model_decoder = MyBetaVAEDecoder(in_channels, z_dim, beta)\n",
    "model_encoder.load_state_dict(state_dict=checkpoint['model'])\n",
    "model_decoder.load_state_dict(state_dict=checkpoint['model'])\n",
    "model_encoder.to(device)\n",
    "model_decoder.to(device)\n",
    "print(summary(model, (3, 64, 64)))\n",
    "model.eval()\n",
    "model_encoder.eval()\n",
    "model_decoder.eval()\n",
    "\n",
    "### Save PyTorch Model\n",
    "PT_MODEL_PATH = \"./models/best_model.pt\"\n",
    "torch.save(model, PT_MODEL_PATH)\n",
    "PT_MODEL_PATH_ENCODER = \"./models/best_model_encoder.pt\"\n",
    "torch.save(model, PT_MODEL_PATH_ENCODER)\n",
    "PT_MODEL_PATH_DECODER = \"./models/best_model_decoder.pt\"\n",
    "torch.save(model, PT_MODEL_PATH_DECODER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tW2khBjNEcmq",
    "outputId": "eae86673-371b-4fcf-b867-b292a149ba7f"
   },
   "outputs": [],
   "source": [
    "### Convert PyTorch to ONNX Model\n",
    "dummy_input = torch.ones(batch_size,3,64,64).to(device)\n",
    "dynamic_axes = {'input' : {0 : 'batch_size'}, 'output' : {0 : 'batch_size'}}\n",
    "ONNX_MODEL_PATH = \"./models/best_model.onnx\"\n",
    "QI_ONNX_MODEL_PATH = \"./models/QI-best_model.onnx\"\n",
    "torch.onnx.export(model,\n",
    "                  dummy_input,\n",
    "                  ONNX_MODEL_PATH,\n",
    "                  input_names = ['input'],\n",
    "                  output_names = ['output'],\n",
    "                  dynamic_axes=dynamic_axes,\n",
    "                  opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZA0n9zzuRm7l"
   },
   "outputs": [],
   "source": [
    "dummy_input = torch.ones(batch_size, 3,64,64).to(device)\n",
    "dynamic_axes = {'input' : {0 : 'batch_size'}, 'output' : {0 : 'batch_size'}}\n",
    "ONNX_MODEL_PATH_ENCODER = \"./models/best_model_encoder.onnx\"\n",
    "QI_ONNX_MODEL_PATH_ENCODER = \"./models/QI-best_model_encoder.onnx\"\n",
    "torch.onnx.export(model_encoder,\n",
    "                  dummy_input,\n",
    "                  ONNX_MODEL_PATH_ENCODER,\n",
    "                  input_names = ['input'],\n",
    "                  output_names = ['output'],\n",
    "                  dynamic_axes=dynamic_axes,\n",
    "                  opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTJMgWonEeMZ"
   },
   "outputs": [],
   "source": [
    "dummy_input = torch.ones(batch_size,128).to(device)\n",
    "dynamic_axes = {'input' : {0 : 'batch_size'}, 'output' : {0 : 'batch_size'}}\n",
    "ONNX_MODEL_PATH_DECODER = \"./models/best_model_decoder.onnx\"\n",
    "QI_ONNX_MODEL_PATH_DECODER = \"./models/QI-best_model_decoder.onnx\"\n",
    "torch.onnx.export(model_decoder,\n",
    "                  dummy_input,\n",
    "                  ONNX_MODEL_PATH_DECODER,\n",
    "                  input_names = ['input'],\n",
    "                  output_names = ['output'],\n",
    "                  dynamic_axes=dynamic_axes,\n",
    "                  opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ei_DI6Sy4pn"
   },
   "outputs": [],
   "source": [
    "kwargs = {\"op_types_to_quantize\":     [],\n",
    "          \"per_channel\":              False,\n",
    "          \"reduce_range\":             False,\n",
    "          \"activation_type\":          onnxruntime.quantization.QuantType.QUInt8,\n",
    "          \"weight_type\":              onnxruntime.quantization.QuantType.QUInt8,\n",
    "          \"nodes_to_quantize\":        [],\n",
    "          \"nodes_to_exclude\":         [],\n",
    "          \"use_external_data_format\": False}\n",
    "\n",
    "onnxruntime.quantization.quantize_dynamic(ONNX_MODEL_PATH, \n",
    "                                          QI_ONNX_MODEL_PATH, \n",
    "                                          **kwargs)\n",
    "onnxruntime.quantization.quantize_dynamic(ONNX_MODEL_PATH_ENCODER, \n",
    "                                          QI_ONNX_MODEL_PATH_ENCODER, \n",
    "                                          **kwargs)\n",
    "onnxruntime.quantization.quantize_dynamic(ONNX_MODEL_PATH_DECODER, \n",
    "                                          QI_ONNX_MODEL_PATH_DECODER, \n",
    "                                          **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXh2zQuOy7Ft",
    "outputId": "be57456e-1827-43e0-e0c3-37cee768e87a"
   },
   "outputs": [],
   "source": [
    "onnx_size_mb   = os.path.getsize(ONNX_MODEL_PATH)/1e6\n",
    "qi_onnx_size_mb = os.path.getsize(QI_ONNX_MODEL_PATH)/1e6\n",
    "\n",
    "print(\"\\nONNX model size (MB):     {:.2f}\".format(onnx_size_mb))\n",
    "print(\"\\nQI-ONNX model size (MB):  {:.2f}\".format(qi_onnx_size_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzYhyipwzGKL"
   },
   "outputs": [],
   "source": [
    "class init_inference:\n",
    "    def __init__(self, session):\n",
    "        self.session = session\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        input_data = image.numpy() # x\n",
    "        input_name  = self.session.get_inputs()[0].name\n",
    "    \n",
    "        return self.session.run(None, {input_name: input_data})\n",
    "\n",
    "def total_latency_fn(tqdm_dataloader):\n",
    "    start = tqdm_dataloader.start_t\n",
    "    stop = tqdm_dataloader.last_print_t\n",
    "    n = tqdm_dataloader.n\n",
    "    \n",
    "    total_latency = (stop - start)\n",
    "    \n",
    "    return total_latency\n",
    "\n",
    "def simple_table(data_multilist, x_label_list, y_label_list):\n",
    "    for i in range(len(y_label_list)+1):\n",
    "        if i == 0:\n",
    "            row = [\"\\t\"]\n",
    "            row.extend(x_label_list)\n",
    "            string = \"\\t\".join(row)\n",
    "        else:\n",
    "            row = [y_label_list[i-1]]\n",
    "            \n",
    "            row.extend([format(x, \".6f\") for x in data_multilist[i-1]])\n",
    "            string = \"\\t\".join(row)\n",
    "            \n",
    "        print(string)\n",
    "        \n",
    "    return None\n",
    "\n",
    "def my_loss(x_cons, x, mu, logvar):\n",
    "    x_cons = torch.Tensor(x_cons)\n",
    "    mu = torch.Tensor(mu)\n",
    "    logvar = torch.Tensor(logvar)\n",
    "    reconstruction_loss = F.mse_loss(x_cons, x, reduction='sum')\n",
    "    kl_div = torch.mean(torch.sum(-0.5 * (1 + logvar - mu ** 2 - logvar.exp()), dim=1), dim=0)\n",
    "    return reconstruction_loss + beta * kl_div, reconstruction_loss, kl_div\n",
    "\n",
    "def plot_statistic(x, y, title, x_label, y_label):\n",
    "\n",
    "    label_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(label_pos, x, color='black', width=0.8)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.xticks(label_pos, y)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def validate(dataloader, session, session_encoder, session_decoder, true_labels):\n",
    "    tqdm_dataloader = tqdm(dataloader)\n",
    "    inference = init_inference(session)\n",
    "    inference_e = init_inference(session_encoder)\n",
    "    inference_d = init_inference(session_decoder)\n",
    "    z_ls = []\n",
    "    cos_ls, l2_ls = [], []\n",
    "    loss_labels, pred_labels = [], []\n",
    "    losses, mses, klds = 0, 0, 0\n",
    "    total_encoder_time = 0\n",
    "    total_decoder_time = 0\n",
    "    cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (images, target) in enumerate(tqdm_dataloader):\n",
    "        \n",
    "        out, z, mu, logvar, _, _ = inference(images) # out, z, time in secs\n",
    "        for z_single in z:\n",
    "            z_ls.append(z_single)\n",
    "        loss, mse, kld = my_loss(out, images, mu, logvar)\n",
    "\n",
    "        losses += loss\n",
    "        mses += mse\n",
    "        klds += kld\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    total_latency = end_time - start_time # secs\n",
    "\n",
    "    for idx, (images, target) in enumerate(tqdm_dataloader):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        z, mu, logvar = inference_e(images) # z, mu, logvar\n",
    "        end_time = time.time()\n",
    "        total_encoder_time += (end_time - start_time)\n",
    "\n",
    "        start_time = time.time()\n",
    "        z = torch.tensor(z)\n",
    "        out = inference_d(z)\n",
    "        end_time = time.time()\n",
    "        total_decoder_time += (end_time - start_time)\n",
    "        print(total_encoder_time, total_decoder_time)\n",
    "    \n",
    "    for i in range(len(z_ls) - 1):\n",
    "\n",
    "        cos_sim = cos(torch.tensor(z_ls[i]), torch.tensor(z_ls[i + 1]))\n",
    "        cos_ls.append(cos_sim.item())\n",
    "        l2 = torch.norm(torch.tensor(z_ls[i]) - torch.tensor(z_ls[i + 1]), 2)\n",
    "        l2_ls.append(l2)\n",
    "        \n",
    "        \n",
    "    # top k prediction\n",
    "    K = true_labels.sum()\n",
    "    topk_idx_true = np.argsort(-np.array(true_labels))[:K]\n",
    "    \n",
    "    cos_argmin_k_idx = np.argsort(np.array(cos_ls))\n",
    "    cos_topk_idx = cos_argmin_k_idx[:K]\n",
    "    \n",
    "    l2_argmax_k_idx = np.argsort(-np.array(l2_ls))\n",
    "    l2_topk_idx = l2_argmax_k_idx[:K]\n",
    "\n",
    "    def predict_topk(topk_idx, topk_idx_true, z_ls):\n",
    "        pred_labels_topk = [0] * (len(z_ls) - 1)\n",
    "        for idx in topk_idx:\n",
    "            pred_labels_topk[idx] = 1\n",
    "        # compute cos top k accuracy\n",
    "        correct_num = 0\n",
    "        for idx in topk_idx:\n",
    "            if idx in topk_idx_true:\n",
    "                correct_num += 1\n",
    "        top_k_acc = correct_num / K\n",
    "\n",
    "        return pred_labels_topk, top_k_acc\n",
    "\n",
    "\n",
    "    cos_pred_labels_topk, cos_topk_acc = predict_topk(cos_topk_idx, topk_idx_true, z_ls)\n",
    "    l2_pred_labels_topk, l2_topk_acc = predict_topk(l2_topk_idx, topk_idx_true, z_ls)\n",
    "\n",
    "\n",
    "    return losses / len(z_ls), mses / len(z_ls), klds / len(z_ls), total_latency, total_encoder_time, total_decoder_time, cos_pred_labels_topk, cos_topk_acc, l2_pred_labels_topk, l2_topk_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "0ac44e63639c4d5eaa6f7cd7622c4cf7",
      "c5d106936a2f43258629e56ad1725cb3",
      "98c0d363820b47608f06f341549c283b",
      "04c49b7cb40243c2b0629978becccb98",
      "cae334615a524f70aa9e9a44e703e13b",
      "c692408d134a46aba471d599ad8e6e15",
      "5aaa44d7b316492981e28085ac30c8f5",
      "16b2faaa458a49ff86e7536df4e4d764"
     ]
    },
    "id": "AJvd3Vjqz5JW",
    "outputId": "66eca799-76ab-450d-97e6-a1373e2f7a32"
   },
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(ONNX_MODEL_PATH)\n",
    "ort_session_encoder = onnxruntime.InferenceSession(ONNX_MODEL_PATH_ENCODER)\n",
    "ort_session_decoder = onnxruntime.InferenceSession(ONNX_MODEL_PATH_DECODER)\n",
    "\n",
    "losses, mses, klds, total_latency, total_encoder_time, total_decoder_time, cos_pred_labels_topk, cos_topk_acc, l2_pred_labels_topk, l2_topk_acc = validate(dev_loader, ort_session, ort_session_encoder, ort_session_decoder, np.array(true_labels))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dpXhX6iHyEr",
    "outputId": "5758b8f4-0baf-4c75-dcbd-bef1e22abf64"
   },
   "outputs": [],
   "source": [
    "losses, mses, klds, total_latency, total_encoder_time, total_decoder_time, cos_topk_acc, l2_topk_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgCBzALhHexP"
   },
   "outputs": [],
   "source": [
    "# accuracy_score      = sklearn.metrics.accuracy_score(true_labels[:len(pred_labels)], pred_labels)\n",
    "# recall_score      = sklearn.metrics.recall_score(true_labels[:len(pred_labels)], pred_labels)\n",
    "# precision_score      = sklearn.metrics.precision_score(true_labels[:len(pred_labels)], pred_labels)\n",
    "# print(accuracy_score, recall_score, precision_score)\n",
    "\n",
    "# sklearn.metrics.classification_report(true_labels[:len(pred_labels)], pred_labels)\n",
    "print(sklearn.metrics.classification_report(true_labels[:len(cos_pred_labels_topk)], cos_pred_labels_topk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzURtiKKNvY5"
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(true_labels[:len(l2_pred_labels_topk)], l2_pred_labels_topk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6b0fb85fe1e64e9b8306f72d0158b573",
      "244d2b2a346240f59a99e1edc8c48803",
      "5ea95ca46a4048d983ed6abd209e05d1",
      "d858cb6422824852a7e8076d3eb1fd25",
      "325426b2d2e24ceb931627e0ce369c29",
      "142636545901495e92b45adf8822204b",
      "6e77208534ef4479961d3b5b10fc0883",
      "211c3a57ad64403e8c9a71223be8f43d",
      "8e1fa0c14dec4a269e238b539dafad4d"
     ]
    },
    "id": "uZ2gKUabz8yW",
    "outputId": "8301faab-c7e7-4420-82d3-cd293c5ae43b"
   },
   "outputs": [],
   "source": [
    "qi_ort_session = onnxruntime.InferenceSession(QI_ONNX_MODEL_PATH)\n",
    "qi_ort_session_encoder = onnxruntime.InferenceSession(QI_ONNX_MODEL_PATH_ENCODER)\n",
    "qi_ort_session_decoder = onnxruntime.InferenceSession(QI_ONNX_MODEL_PATH_DECODER)\n",
    "\n",
    "qi_losses, qi_mses, qi_klds, qi_total_latency, qi_total_encoder_time, qi_total_decoder_time, qi_cos_pred_labels_topk, qi_cos_topk_acc, qi_l2_pred_labels_topk, qi_l2_topk_acc = validate(dev_loader, qi_ort_session, qi_ort_session_encoder, qi_ort_session_decoder, np.array(true_labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bv17oPr_3o7A",
    "outputId": "2266d726-28ed-42dd-87df-43388a72ff07"
   },
   "outputs": [],
   "source": [
    "qi_losses, qi_mses, qi_klds, qi_total_latency, qi_total_encoder_time, qi_total_decoder_time, qi_cos_topk_acc, qi_l2_topk_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKY2Cr1MHexQ",
    "outputId": "23f91022-bdbe-4132-9617-1e3500f32a06"
   },
   "outputs": [],
   "source": [
    "# qi_accuracy_score   = sklearn.metrics.accuracy_score(true_labels[:len(qi_pred_labels)], qi_pred_labels)\n",
    "# qi_recall_score   = sklearn.metrics.recall_score(true_labels[:len(qi_pred_labels)], qi_pred_labels)\n",
    "# qi_precision_score   = sklearn.metrics.precision_score(true_labels[:len(qi_pred_labels)], qi_pred_labels)\n",
    "# print(qi_accuracy_score, qi_recall_score, qi_precision_score)\n",
    "\n",
    "# sklearn.metrics.classification_report(true_labels[:len(qi_pred_labels)], qi_pred_labels)\n",
    "print(sklearn.metrics.classification_report(true_labels[:len(qi_cos_pred_labels_topk)], qi_cos_pred_labels_topk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiMrjezwQTdH"
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(true_labels[:len(qi_l2_pred_labels_topk)], qi_l2_pred_labels_topk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4lkaRdqHexQ",
    "outputId": "a523f00b-474c-410e-e2b7-95c4edb34193"
   },
   "outputs": [],
   "source": [
    "len(pred_labels)#, len(qi_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_cHskrP0At2",
    "outputId": "c013b433-05f3-4eb6-e7b5-a4929e94ddc0"
   },
   "outputs": [],
   "source": [
    "# qi_losses, qi_mses, qi_klds\n",
    "print('Validation loss results are below.\\n')\n",
    "\n",
    "simple_table(\n",
    "    data_multilist = [[losses, mses, klds],\n",
    "                      [qi_losses, qi_mses, qi_klds]],\n",
    "    x_label_list = [\"total loss\", \"mse        \", \"kld\"],\n",
    "    y_label_list = [\"Float32 \", \"IntegerOps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "enpKGXdW0FNN",
    "outputId": "964de94d-4894-48a4-bc6d-88f8068fcc95"
   },
   "outputs": [],
   "source": [
    "x = [losses, qi_losses, mses, qi_mses, klds, qi_klds]\n",
    "y = ['Float32-Total Loss','IntegerOps-Total Loss', 'Float32-MSE','IntegerOps-MSE', 'Float32-KLD','IntegerOps-KLD',]\n",
    "title = \"Loss Results\"\n",
    "x_label = \"Model Type\"\n",
    "y_label = \"Loss\"\n",
    "    \n",
    "plot_statistic(x, y, title, x_label, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5QhmVSfn0HNm",
    "outputId": "e74db846-e902-4c77-f06b-9246d99ba4d3"
   },
   "outputs": [],
   "source": [
    "# last one in true_labels not used\n",
    "accuracy_score      = sklearn.metrics.accuracy_score(true_labels[:len(pred_labels)], pred_labels)\n",
    "qi_accuracy_score   = sklearn.metrics.accuracy_score(true_labels[:len(qi_pred_labels)], qi_pred_labels)\n",
    "\n",
    "recall_score      = sklearn.metrics.recall_score(true_labels[:len(pred_labels)], pred_labels)\n",
    "qi_recall_score   = sklearn.metrics.recall_score(true_labels[:len(qi_pred_labels)], qi_pred_labels)\n",
    "\n",
    "precision_score      = sklearn.metrics.precision_score(true_labels[:len(pred_labels)], pred_labels)\n",
    "qi_precision_score   = sklearn.metrics.precision_score(true_labels[:len(qi_pred_labels)], qi_pred_labels)\n",
    "\n",
    "print('Validation accuracy results are below.\\n')\n",
    "\n",
    "simple_table(\n",
    "    data_multilist = [[accuracy_score, precision_score, recall_score] ,\n",
    "                      [qi_accuracy_score, qi_precision_score, qi_recall_score]],\n",
    "    x_label_list = [\"Accuracy\", \"Precision\", \"Recall\"],\n",
    "    y_label_list = [\"Float32 \", \"IntegerOps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NunLn3AtKkPM",
    "outputId": "79640e16-fad0-4ffb-c7a6-c80e59059308"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(true_labels[:len(pred_labels)], pred_labels), confusion_matrix(true_labels[:len(qi_pred_labels)], qi_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "TIlzEWil0NOm",
    "outputId": "13c32986-b0df-4958-ad97-4e4ffe87e92b"
   },
   "outputs": [],
   "source": [
    "x = [accuracy_score, qi_accuracy_score, precision_score, qi_precision_score, recall_score, qi_recall_score]\n",
    "y = ['Accuracy-Float32','Accuracy-IntegerOps', 'Precision-Float32','Precision-IntegerOps', 'Recall-Float32','Recall-IntegerOps']\n",
    "title = \"Scene Change Detection Accuracy, Precision, Recall\"\n",
    "x_label = \"Model Type\"\n",
    "y_label = \"Metric\"\n",
    "    \n",
    "plot_statistic(x, y, title, x_label, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSLjfZiAKux_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_UHxv850PtA",
    "outputId": "b8ffbe0a-b60b-47d4-c109-fc601b06b5cd"
   },
   "outputs": [],
   "source": [
    "print('Model sizes are below.\\n')\n",
    "\n",
    "simple_table(\n",
    "    data_multilist = [[onnx_size_mb] ,\n",
    "                      [qi_onnx_size_mb]],\n",
    "    x_label_list = [\"Baseline\"],\n",
    "    y_label_list = [\"Float32 \", \"IntegerOps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "FDFdDeLk0SNp",
    "outputId": "31b3f4c2-f4d2-4da5-d297-563d2a665359"
   },
   "outputs": [],
   "source": [
    "x = [onnx_size_mb, qi_onnx_size_mb]\n",
    "y = ['Float32', 'IntegerOps']\n",
    "title = \"Model Size\"\n",
    "x_label = \"Model Type\"\n",
    "y_label = \"Model Size (MB)\"\n",
    "    \n",
    "plot_statistic(x, y, title, x_label, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoSWD3gU0Usg",
    "outputId": "098afb11-eaa8-42e3-8f0c-dd200905a744"
   },
   "outputs": [],
   "source": [
    "print('Validation latency results are below.\\n')\n",
    "\n",
    "simple_table(\n",
    "    data_multilist = [[total_latency   , total_encoder_time, total_decoder_time],\n",
    "                      [qi_total_latency, qi_total_encoder_time, qi_total_decoder_time]], \n",
    "    x_label_list = [\"Total Latency\", \"Encoder Latency\", \"Decoder Latency\"], \n",
    "    y_label_list = [\"Float32 \", \"IntegerOps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "k3__9Epr0Vbp",
    "outputId": "b94da6e6-8e10-4bfb-8dbb-00c61386b5a9"
   },
   "outputs": [],
   "source": [
    "x = [total_latency, qi_total_latency, total_encoder_time, qi_total_encoder_time, total_decoder_time, qi_total_decoder_time]\n",
    "y = ['Float32-Total', 'IntegerOps-Total', 'Float32-Encoder', 'IntegerOps-Encoder', 'Float32-Decoder', 'IntegerOps-Decoder',]\n",
    "title = \"Latency Results\"\n",
    "x_label = \"Model Type\"\n",
    "y_label = \"Latency (sec)\"\n",
    "\n",
    "plot_statistic(x, y, title, x_label, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-Duseq50lnP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gbnazo8v0lfN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "MyBetaVAE_quantization_batchsize512.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python382jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04c49b7cb40243c2b0629978becccb98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16b2faaa458a49ff86e7536df4e4d764",
      "placeholder": "​",
      "style": "IPY_MODEL_5aaa44d7b316492981e28085ac30c8f5",
      "value": " 0/51 [00:00&lt;?, ?it/s]"
     }
    },
    "0ac44e63639c4d5eaa6f7cd7622c4cf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98c0d363820b47608f06f341549c283b",
       "IPY_MODEL_04c49b7cb40243c2b0629978becccb98"
      ],
      "layout": "IPY_MODEL_c5d106936a2f43258629e56ad1725cb3"
     }
    },
    "142636545901495e92b45adf8822204b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16b2faaa458a49ff86e7536df4e4d764": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "211c3a57ad64403e8c9a71223be8f43d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "244d2b2a346240f59a99e1edc8c48803": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "325426b2d2e24ceb931627e0ce369c29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5aaa44d7b316492981e28085ac30c8f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ea95ca46a4048d983ed6abd209e05d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_142636545901495e92b45adf8822204b",
      "max": 203,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_325426b2d2e24ceb931627e0ce369c29",
      "value": 203
     }
    },
    "6b0fb85fe1e64e9b8306f72d0158b573": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5ea95ca46a4048d983ed6abd209e05d1",
       "IPY_MODEL_d858cb6422824852a7e8076d3eb1fd25"
      ],
      "layout": "IPY_MODEL_244d2b2a346240f59a99e1edc8c48803"
     }
    },
    "6e77208534ef4479961d3b5b10fc0883": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98c0d363820b47608f06f341549c283b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c692408d134a46aba471d599ad8e6e15",
      "max": 51,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cae334615a524f70aa9e9a44e703e13b",
      "value": 0
     }
    },
    "c5d106936a2f43258629e56ad1725cb3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c692408d134a46aba471d599ad8e6e15": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cae334615a524f70aa9e9a44e703e13b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d858cb6422824852a7e8076d3eb1fd25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_211c3a57ad64403e8c9a71223be8f43d",
      "placeholder": "​",
      "style": "IPY_MODEL_6e77208534ef4479961d3b5b10fc0883",
      "value": " 203/203 [02:36&lt;00:00,  1.29it/s]"
     }
    }
   }
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}